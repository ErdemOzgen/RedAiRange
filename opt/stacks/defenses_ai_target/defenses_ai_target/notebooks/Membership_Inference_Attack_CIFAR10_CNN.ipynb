{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736ca37b",
   "metadata": {},
   "source": [
    "# Example Membership Inference Attack using ART\n",
    "\n",
    "In this notebook, we will use ART, which trains shadow models to generate a meta-dataset for membership inference and conduct the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec0b730-af95-4f8b-b206-2e9375404eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n",
      "1.17.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import art\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "print(art.__version__)\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8241c00",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Data\n",
    "\n",
    "We'll load the CIFAR-10 data and split it for training the target and shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6a6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Split the data for target and shadow models\n",
    "# Assuming 25% for target model and 75% for shadow models\n",
    "x_target = x_train[:12500]\n",
    "y_target = y_train[:12500]\n",
    "x_shadow = x_train[12500:]\n",
    "y_shadow = y_train[12500:]\n",
    "\n",
    "# Further split target data for training and testing\n",
    "target_train_size = len(x_target) // 2\n",
    "x_target_train = x_target[:target_train_size]\n",
    "y_target_train = y_target[:target_train_size]\n",
    "x_target_test = x_target[target_train_size:]\n",
    "y_target_test = y_target[target_train_size:]\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_target_train, x_target_test, x_shadow = x_target_train / 255.0, x_target_test / 255.0, x_shadow / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cfdb1",
   "metadata": {},
   "source": [
    "## Load Pre-trained Target Model\n",
    "\n",
    "Load the pre-trained target model using the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f18ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your pre-trained CNN model\n",
    "model = tf.keras.models.load_model('../models/simple-cifar10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e52c9",
   "metadata": {},
   "source": [
    "## Train Shadow Models\n",
    "\n",
    "We will train multiple shadow models to simulate the behavior of the target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f56a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples\n",
      "Epoch 1/5\n",
      "18750/18750 [==============================] - 1s 67us/sample - loss: 1.6703 - accuracy: 0.3919\n",
      "Epoch 2/5\n",
      "18750/18750 [==============================] - 1s 79us/sample - loss: 1.3434 - accuracy: 0.5164\n",
      "Epoch 3/5\n",
      "18750/18750 [==============================] - 1s 77us/sample - loss: 1.2032 - accuracy: 0.5772\n",
      "Epoch 4/5\n",
      "18750/18750 [==============================] - 2s 81us/sample - loss: 1.0926 - accuracy: 0.6201\n",
      "Epoch 5/5\n",
      "18750/18750 [==============================] - 2s 84us/sample - loss: 1.0028 - accuracy: 0.6500\n",
      "Train on 18750 samples\n",
      "Epoch 1/5\n",
      "18750/18750 [==============================] - 1s 77us/sample - loss: 1.7073 - accuracy: 0.3803\n",
      "Epoch 2/5\n",
      "18750/18750 [==============================] - 1s 76us/sample - loss: 1.3474 - accuracy: 0.5188\n",
      "Epoch 3/5\n",
      "18750/18750 [==============================] - 1s 71us/sample - loss: 1.1951 - accuracy: 0.5834\n",
      "Epoch 4/5\n",
      "18750/18750 [==============================] - 1s 65us/sample - loss: 1.0766 - accuracy: 0.6229\n",
      "Epoch 5/5\n",
      "18750/18750 [==============================] - 1s 65us/sample - loss: 0.9956 - accuracy: 0.6546\n",
      "Train on 18750 samples\n",
      "Epoch 1/5\n",
      "18750/18750 [==============================] - 2s 87us/sample - loss: 1.7094 - accuracy: 0.3796\n",
      "Epoch 2/5\n",
      "18750/18750 [==============================] - 1s 74us/sample - loss: 1.3442 - accuracy: 0.5161\n",
      "Epoch 3/5\n",
      "18750/18750 [==============================] - 1s 64us/sample - loss: 1.1827 - accuracy: 0.5853\n",
      "Epoch 4/5\n",
      "18750/18750 [==============================] - 1s 57us/sample - loss: 1.0804 - accuracy: 0.6209\n",
      "Epoch 5/5\n",
      "18750/18750 [==============================] - 1s 55us/sample - loss: 1.0053 - accuracy: 0.6473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "\n",
    "def create_shadow_model():\n",
    "    shadow_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    shadow_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return shadow_model\n",
    "\n",
    "# Train shadow models\n",
    "num_shadow_models = 3\n",
    "shadow_models = []\n",
    "for _ in range(num_shadow_models):\n",
    "    shadow_model = create_shadow_model()\n",
    "    x_shadow_train, x_shadow_test, y_shadow_train, y_shadow_test = train_test_split(x_shadow, y_shadow, test_size=0.5)\n",
    "    shadow_model.fit(x_shadow_train, y_shadow_train, epochs=5, verbose=True)\n",
    "    shadow_models.append((shadow_model, (x_shadow_train, y_shadow_train), (x_shadow_test, y_shadow_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d117f-0a59-4192-bf1d-c96b04b3141e",
   "metadata": {},
   "source": [
    "## Generate Shadow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2992cfb3-fffe-4120-8092-6dea7cf434b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanni/.local/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Generate shadow dataset\n",
    "member_x, member_y, member_predictions = [], [], []\n",
    "nonmember_x, nonmember_y, nonmember_predictions = [], [], []\n",
    "\n",
    "for shadow_model, (x_shadow_train, y_shadow_train), (x_shadow_test, y_shadow_test) in shadow_models:\n",
    "    member_preds = shadow_model.predict(x_shadow_train)\n",
    "    nonmember_preds = shadow_model.predict(x_shadow_test)\n",
    "    \n",
    "    member_x.append(x_shadow_train)\n",
    "    member_y.append(y_shadow_train)\n",
    "    member_predictions.append(member_preds)\n",
    "    \n",
    "    nonmember_x.append(x_shadow_test)\n",
    "    nonmember_y.append(y_shadow_test)\n",
    "    nonmember_predictions.append(nonmember_preds)\n",
    "\n",
    "member_x = np.concatenate(member_x)\n",
    "member_y = np.concatenate(member_y)\n",
    "member_predictions = np.concatenate(member_predictions)\n",
    "\n",
    "nonmember_x = np.concatenate(nonmember_x)\n",
    "nonmember_y = np.concatenate(nonmember_y)\n",
    "nonmember_predictions = np.concatenate(nonmember_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4601f7",
   "metadata": {},
   "source": [
    "## Conduct the Attack\n",
    "\n",
    "We can now use the shadow models to train the attack model for membership inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6423-63ad-47da-9cba-96c9bf084a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2a9e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanni/.local/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership inference on training data (member inference): [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Membership inference on test data (non-member inference): [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "# Wrap the Keras model in an ART classifier\n",
    "classifier = KerasClassifier(model=model, clip_values=(0, 1))\n",
    "\n",
    "# Train the black-box membership inference attack\n",
    "attack = MembershipInferenceBlackBox(classifier, attack_model_type=\"nn\")\n",
    "attack.fit(member_x, member_y, nonmember_x, nonmember_y, member_predictions, nonmember_predictions)\n",
    "\n",
    "# Evaluate the attack\n",
    "member_infer = attack.infer(x_target_train, y_target_train)\n",
    "nonmember_infer = attack.infer(x_target_test, y_target_test)\n",
    "# Display results - 1 is 100% success 0 is 0% sc\n",
    "print(\"Membership inference on training data (member inference):\", member_infer)\n",
    "print(\"Membership inference on test data (non-member inference):\", nonmember_infer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeebce79",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
