{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa068ef-9b7b-4a61-a4b8-58857c160278",
   "metadata": {},
   "source": [
    "# Adversarial Evasion Attacks on BERT and NLP using TextAttack \n",
    "\n",
    "This notebook provides a simple sample of how to stage an NLP evasion attack against BERT models using TextAttack for two examples 1) Sentiment Analysis and 2) Natural Language Inference (NLI). The workflow is as follows:\n",
    "- Setup dependencies\n",
    "- Load the target model and tokeniser\n",
    "- Create a Text attack model wrapper\n",
    "- Create an attack for the wrapper using the  TextFooler TextAttack recipe\n",
    "- Test the attack on a custom text/pair of texts\n",
    "- Test the attack on a random sample from the test dataset\n",
    "- Show how to generate and save geenerated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d10185-4483-4915-9286-9659cd4b6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import random\n",
    "from textattack. models.wrappers import HuggingFaceModelWrapper, ModelWrapper\n",
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack.datasets import HuggingFaceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9ee41-69ab-46a0-b77e-796e0df2a7b7",
   "metadata": {},
   "source": [
    "### Example 1 - Attack on sentiment analysis with IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36acabe-4c0e-4f3f-9a21-788c3edaea83",
   "metadata": {},
   "source": [
    "##### Load the model and tokenizer and wrap them with a TextAttack wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692336ec-0a25-431a-9dce-16d4be9ebe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target pre-trained model for sentiment analysis and a tokeniser\n",
    "imdb_model = transformers.AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_model_wrapper = HuggingFaceModelWrapper(imdb_model, imdb_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955d56f-4756-4f1e-bb29-558e6e810ac1",
   "metadata": {},
   "source": [
    "##### Sample custom Text wrapper for non-HF models - not used, given as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb321d9-9d97-457e-96e7-1150d32fc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a custom model Wrapper with TextAttack's ModelWrapper \n",
    "# Useful if you're testing a non-Hugging Face model\n",
    "# But not used here - cited in case you use own local models\n",
    "class CustomModelWrapper(ModelWrapper):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __call__(self, text_input_list):\n",
    "        inputs = self.tokenizer(text_input_list, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs.logits.numpy()\n",
    "    \n",
    "model_wrapper2 = CustomModelWrapper(imdb_model, imdb_tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b3da7-ef4b-4917-9ba0-d8f88cf0e87c",
   "metadata": {},
   "source": [
    "##### Setup and test the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200dcc4-70fa-46ec-9370-c5b5dcec5b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose the attack method\n",
    "imdb_attack = TextFoolerJin2019.build(imdb_model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6be55-700b-4e2f-9b75-33207ba450e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the attack with your own simple text\n",
    "input_text = \"I really enjoyed the new movie that came out last month.\"\n",
    "label = 1 #Positive - this the current valid classification\n",
    "attack_result = imdb_attack.attack(input_text, label)\n",
    "#printing the attack result prints both original and adversarial classifications\n",
    "print(attack_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e636c-dd83-4c89-a5fb-ea25cf9bf3db",
   "metadata": {},
   "source": [
    "##### Test attack with IMDB and Glue/SST2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65904c3-18e7-4dcd-a9f2-f171f1247fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup a loop to test with a dataset\n",
    "def test_random_dataset_entry(attack, dataset, text_pairs=False):\n",
    "    random_entry = random.choice(dataset)\n",
    "    if text_pairs:\n",
    "        premise = random_entry['premise']\n",
    "        hypothesis = random_entry['hypothesis']\n",
    "        input_text = f\"{premise} BERT {hypothesis}\"\n",
    "        label = random_entry['label']\n",
    "    else:\n",
    "        input_text = list(random_entry[0].values())[0]\n",
    "        label = random_entry[1]\n",
    "    attack_result = attack_result = attack.attack(input_text, label)\n",
    "    return attack_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c1979-9c76-4e76-82a2-d1a3b6d0c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the attack with random test entries from the imdb dataset\n",
    "imdb_dataset =  HuggingFaceDataset(\"imdb\", split=\"test\")\n",
    "attack_result =test_random_dataset_entry(imdb_attack, imdb_dataset)\n",
    "print(attack_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155ed1f-be93-486a-8049-2b671592ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset_iterator = iter(dataset)\n",
    "#for example_index in range(5):\n",
    "#    example, label = next(dataset_iterator)\n",
    "#    attack_result = attack.attack(label, ground_truth_output)\n",
    "#    print(attack_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab64d6-d62d-4922-94b7-c17872d48cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test the attack with a non-IMDB dataset, using the sst2 subset of the GLUE dataset.\n",
    "glue_dataset = HuggingFaceDataset('glue', 'sst2', split='test')\n",
    "attack_result =test_random_dataset_entry(imdb_attack, glue_dataset)\n",
    "print(attack_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6931b44-40a0-402f-ba26-fe20878ef349",
   "metadata": {},
   "source": [
    "## Example 2 - Attack on language inference using SLNI\n",
    "\n",
    "Adversarial attack using  the *bert-base-uncased-snli model*, which is trained specifically for Natural Language Inference (NLI)and the SNLI (Stanford Natural Language Inference) dataset itself. This dataset is ideally suited for the model since it directly corresponds to the training data used for the model.\n",
    "\n",
    "#### SNLI Dataset Overview \n",
    "\n",
    "The SNLI dataset is a collection of sentence pairs annotated with one of three labels: entailment, contradiction, or neutral. These labels represent the relationship between a \"premise\" and a \"hypothesis\" sentence:\n",
    "\n",
    "- *Entailment*: The hypothesis is a true statement given the premise.\n",
    "- *Contradiction*: The hypothesis is a false statement given the premise.\n",
    "- *Neutral*: The truth of the hypothesis is undetermined given the premise.\n",
    "\n",
    "Both model and dataset use a pair of input texts (Hypothesis/Premise) and you need to pass them either as and Ordered Dictionary or as a string using the BERT convention <hypothesis>SEP<premise>.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa3796-43ef-4962-8ae7-d9bed2f501ce",
   "metadata": {},
   "source": [
    "##### Model, Tokenizer, and wrapper setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c152dac-e81d-4164-a0a2-999e3275bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "slni_model = transformers.AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-snli\")\n",
    "slni_tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-snli\")\n",
    "# Wrap the model for TextAttack\n",
    "slni_model_wrapper = HuggingFaceModelWrapper(slni_model, slni_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714892a8-edba-4130-aa1e-2c8394b260b7",
   "metadata": {},
   "source": [
    "##### Setup and test the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68cd880-be03-418a-9d2d-d5b3a8f0fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the attack\n",
    "slni_attack = TextFoolerJin2019.build(slni_model_wrapper)\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Test with a single random pair\n",
    "input_text_pair = OrderedDict([\n",
    "    (\"premise\", \"A man inspects the uniform of a figure in some East Asian country.\"),\n",
    "    (\"hypothesis\", \"The man is sleeping\")\n",
    "])\n",
    "label = 0  # Typically for NLI: 0 - contradiction, 1 - neutral, 2 - entailment\n",
    "attack_result = slni_attack.attack(input_text_pair, label)\n",
    "\n",
    "print(attack_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca0081-e3e7-471e-8cf7-949762fded3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "slni_dataset = load_dataset(\"snli\", split='test')\n",
    "attack_result = test_random_dataset_entry(slni_attack, slni_dataset, text_pairs=True)\n",
    "print(attack_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704563e-d0fe-466d-9220-59050a677caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
