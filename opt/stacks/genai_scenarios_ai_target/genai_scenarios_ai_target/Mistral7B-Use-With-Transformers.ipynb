{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a747a88",
   "metadata": {},
   "source": [
    "# How to use an LLM from Hugging Face\n",
    "It assumes that you have a valid Hugging Face token stored as an environment variable i.e. 'HF_TOKEN=[token]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531fbb13-5006-4b51-beee-7f25f9a15a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f1a7b6-e476-41b9-ae33-8d3c46dea83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanni/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470079e8f7f34319b8ba2ca11080d792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "bnb_config = BitsAndBytesConfig(  \n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "\n",
    "\n",
    "model_checkpoint = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    load_in_4bit=True,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104566e-0808-481e-b20c-f6573ffcdd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55f1e45-aeb2-48a6-ab17-6cc9cc939b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b938ed-5321-4364-9f15-aed96b314a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer = tokenizer, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b46ef8-582e-4f71-bafa-0675ebd8b593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please suggest a recipe to reduce cholesterol and lose weight.\n",
      "\n",
      "Answer: Here is a simple and effective recipe that can help reduce cholesterol levels and aid in weight loss. This recipe is for a Chickpea Salad, which is rich in fiber, protein, and healthy fats.\n",
      "\n",
      "Ingredients:\n",
      "- 1 can (15 oz) chickpeas, drained and rinsed\n",
      "- 1 cup chopped cucumber\n",
      "- 1 cup chopped tomatoes\n",
      "- \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please suggest a recipe to reduce cholesterol and lose weight\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a24b0-9767-4d9b-817f-8af5943d5025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
